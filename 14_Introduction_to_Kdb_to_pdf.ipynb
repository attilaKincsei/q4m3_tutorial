{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. Introduction to Kdb+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __[Wikipedia on Kdb+](https://en.wikipedia.org/wiki/Kdb%2B)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kdb+, as well as q, is written in k.\n",
    "- Kdb+ is the data persistence part of q.\n",
    "- Kdb+ is a relational database which is:\n",
    "    - __CSDB__ - column-store (columnar) (algol-like db)\n",
    "    - __TSDB__ - time series database\n",
    "    - __IMDB__ - in-memory abilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CSDB means faster seeking in data stored on hard disks\n",
    "- CSDB is slower on retrieving full rows of tables\n",
    "    - A RSDB retrieves a row in a single disk read (whole row operations are rare)\n",
    "    - A CSDB retrieves a row in multiple disk operations\n",
    "- OLTP-focused RDBMSs are more row oriented\n",
    "- OLAP-focused RDBMSs are a balance of row-oriented and column-oriented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __[OLTP vs OLAP](https://stackoverflow.com/a/21900244)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OLTP AND OLAP are different approaches to answer Multi-Dimensional Analytical (MDA) queries efficiently in computing\n",
    "- __OLTP__:\n",
    "    - stands for __On-line Transaction Processing__, transaction meaning an atomic change in the state of data.\n",
    "    - __temporary data__: focussed on the operation of a particular system: frequent changes in data,\n",
    "    - __volume of transactions (INSERT, UPDATE, DELETE)__: large number of short on-line transactions,\n",
    "    - main emphasis is on:\n",
    "        - very fast query __processing of full records__\n",
    "        - maintaining __data integrity__ in multi-access environments and\n",
    "    - __measure of effectiveness__: number of transactions per second.\n",
    "    - __OLTP databases contain__\n",
    "         - there is detailed and __current data__,\n",
    "         - incorporates an __entity model__: a schema used to store transactional databases\n",
    "             in the 3rd normal form (3NF).\n",
    "    - __Main goals / focus__:\n",
    "         - availability\n",
    "         - speed\n",
    "         - concurrency\n",
    "         - recoverability\n",
    "    - __Characteristics of OLTP__:\n",
    "         - insert and update intensive\n",
    "         - OLTP applications are used concurrently by a larga volume of users\n",
    "         - because of the above caracteristics, data integrity is harder to maintain in an OLTP database than in an OLAP database\n",
    "         - __Queries__ typically:\n",
    "             - access individual records (full rows) and\n",
    "             - are signifacantly less complex than those in an OLAP database\n",
    "    - __Typical applications of OLTP__:\n",
    "         - ATM: commercial transaction processing application\n",
    "             - the same data (bank account balance) is updated frequently\n",
    "         - Inventory management application of a web store:\n",
    "             - Number of items available in the store is updated continuously as customers buy them\n",
    "             \n",
    "\n",
    "- __OLAP__:\n",
    "    - stands for __On-line Analytical Processing__\n",
    "    - __fixed data__: deals with Historical Data or Archival Data.\n",
    "    - __volume of transactions__: relatively low,\n",
    "    - __Queries__:\n",
    "        - very complex\n",
    "        - involve aggregations, joins, where and group by clauses.\n",
    "        - need to access large amount of data in the database\n",
    "    - __Measure of effectiveness__: response time\n",
    "    - __Usage__: Data Mining techniques, time series analysis\n",
    "    - __OLAP databases contain__:\n",
    "        - aggregated, historical data,\n",
    "        - stored in multi-dimensional schemas (usually star schema).\n",
    "    - OLAP databases / data warehouses contain [3 types of data](https://docs.oracle.com/cd/B10500_01/olap.920/a95295/designd4.htm):\n",
    "        - historical data\n",
    "        - derived data: generated from historical data using mathematical operations and data transformation\n",
    "        - metadata: data that describes the data and schema objects\n",
    "            - it is used by applicatons to fetch and compute data correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CSDBs are well suited for OLAP-like workloads (like in data warehouses),\n",
    "    - where highly complex queries are frequently executed over big data\n",
    "- CSDBs have been developed as hybrids capable of OLTP and OLAP operations\n",
    "- RSDBs are better suited for OLTP-like workloads,\n",
    "    - which are more heavily loaded with interactive transactions.\n",
    "- Disadvantages of CSDBs to RSDBs:\n",
    "    - Retrieving entire rows from table\n",
    "    - Transaction-heavy operations (insert, update, delete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.1. Tables in memory and serialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Persist a table with set and read it into memory with get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1.1. Tables and key tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A table is a trasposed column dictionary, in which address slots are reversed but no data is moved\n",
    "- The table schema looks like this: ([] s:`symbol$(); v:`int$())\n",
    "- The type of a table is 98h\n",
    "- The type of a keyed table is 99h\n",
    "- The meta command returns column names, types and attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1.1. Foreign keys and [link colums](https://code.kx.com/v2/wp/the_application_of_foreign_keys_and_linked_columns_in_kdb.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Schema for creating a foreign key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".kin.table1:([id:til 10] col1:10?`5;col2:3*10?1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".kin.table2:([] t1id:`.kin.table1$5 4 7 2 3;date:.z.d+5?30;percent:90+5?20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".kin.table3:([]; t1id:`.kin.table1!(exec id from .kin.table1)?5 4 7 2 3; q:100 101 102 103 109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".kin.table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".kin.table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".kin.table3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A link column is similar to a foreign key:\n",
    "    - its entries are indices of rows in a table\n",
    "    - but you must perform the lookup manually: you have to enumextend the id column then create a dictionary of them\n",
    "- The advantages of link columns:\n",
    "    - The target can be a table or a keyed table\n",
    "    - The target can be the table containing the link column\n",
    "    - __Link columns can be splayed or partitioned, whereas foreign keys cannot__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kt:([id:1001 1002 1003] s:`a`b`c; v:100 200 300)\n",
    "t:([]; id:`kt$1002 1001 1003 1001; q:100 101 102 103) // foreign key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q)tk:([] id:1001 1002 100; s:`a`b`c; v:100 200 300)\n",
    "q)t:([]; id:`tk!(exec id from tk)?1002 1001 1003 1001; q:100 101 102 103) // link column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1.3. Serializing tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __set/get__ to persist and load tables\n",
    "    - set/get is the the general serialization/deserialization feature of q\n",
    "    - a single file is created in the OS file system\n",
    "- \\l can also be used instead of get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(hsym `$dataDir,\"table1\") set .kin.table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".kin.ldtable:get hsym `$dataDir,\"table1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".kin.ldtable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1.4. Operating on serialized tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To execute an operation on a table you can:\n",
    "    - either load it into memory:tInMem:get `fileHandle -> select from tInMem\n",
    "    - or do it directly on the persisted table: select from `fileHandle\n",
    "- Under the hood, __operations are performed in memory in both cases__!!!\n",
    "    - Serialized table must fit into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1.5. The database view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Zero dimensional persisted form: when 1 table = 1 file\n",
    "    - The contents of the table is represented by a dot\n",
    "- Zero dimensional vs higher-dimensional forms: 1 table = multiple files and/or multiple directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of data decomposition in q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tables can be:\n",
    "    - __Splayed__: columns of splayed tables are stored in multiple files\n",
    "    - __Partitioned__: rows of partitiond tables are stored in multiple directories\n",
    "        - columns are stored in different files in an additional subdirectory with the same name as the table\n",
    "    - __Segmented__: rows of a segmented table are stored in multiple directories (that have the same sturcture as the root directory in a partitioned database) on multiple partitions of the hard drive to allow parallel processing of queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.2. Spayed tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Problems with serialized tables:\n",
    "    - __Space complexity__: The entire table must fit into memory on each user's machine\n",
    "    - __Time complexity__ (speed): operations on persisted tables will be slow due to reloading the entire table each time into memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.0. Spaying a table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Splaying is when the columns of tables is persisted in multiple files in one directory:\n",
    "    - A splayed tables corresponds to a directory with the name of the table and\n",
    "    - Each columns corresponds to a file with the name of the column\n",
    "    - The sym file (.d): the only metadata stored is the list of column names, which is serialized to the hidden sym file\n",
    "- Splay tables visualization:\n",
    "    1-dimensional persisted form: a series of dots representing columns\n",
    "- Splaying resolves the memory/reload issue through mapping the columns to the memory:\n",
    "    - Columns are loaded into memory on demand then memory is released when no longer needed\n",
    "- Used case: splay those tables with many columns, since most queries refer to only a handful of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.1. Creating splayed tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To create a splayed table, use\n",
    "    - a directory as a file handle instead of a file name + set/upsert + tableName or\n",
    "    - you can splay it manually\n",
    "- Restrictions on the column types that can be splayed:\n",
    "    - No general lists: simple or compound lists only\n",
    "    - Columns of symbol type must be enumerated\n",
    "    - You cannot splay keyed tables (use link columns instead of keys)\n",
    "    - Same filename cannot exist as the would-be-splayed directory name\n",
    "- To read a splayed table, use\n",
    "    - get + the original directory handle\n",
    "- To read only a column, use:\n",
    "    - get + column file name as a file handle\n",
    "- To list the files in the directory:\n",
    "    - \\ls + the full path __without__ the backtick and the backslash at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".kin.dirHandle:hsym `$dataDir,\"testTrades/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".kin.dirFileName:hsym `$dataDir,\"testTrades\" / this won't work with \\ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".kin.dirHandle set .kin.spTrades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".kin.dirFileName set .kin.mktrades[`goog`ibm`fb`tmobil`amazn`alibaba;100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key `.kin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".kin.mktrades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".kin.tl:get .kin.dirHandle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\ls -a /home/iguana/1_Code/4_jupyter_projects/q4m3_tutorial/data/testTrades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.2. Splayed tables with symbol columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For all splayed and partitioned tables involved in spalying, all symbol columns must be enumerated over the list of symbols that is serialized into the root directory.\n",
    "- For enumerating, use the projected version of built-in .Q.en function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "`:/db/t/ set .Q.en[`:/db;] ([] s1:`a`b`c; v:10 20 30; s2:`x`y`z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.3. Splayed tables with nested columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The only type of nested colulmns that can be splayed is made up of compound lists:\n",
    "    - compound list is a list of simple lists of uniform type\n",
    "    - compund lists are indicated by upper case letters in the type column of meta results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/ function to examine if a column can be splayed\n",
    "canBeSplayed:{where {(ts~1#0h)|1<count ts:distinct `type each`x} each flip x}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.4. Basic operations on splayed tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Map a splayed table to memory by\n",
    "    - either loading it on startap: $$q path/to/splayedTableDir\n",
    "    - or \\l /path/to/splayedTableDir\n",
    "        - only this format works:\n",
    "            - no string,\n",
    "            - no file handle,\n",
    "            - no trailing fwSlash\n",
    "            - no tilde instead of /home/userName\n",
    "- In these cases, tables are only mapped to memory, they are not loaded until an expression is evaluated on them\n",
    "- \\a list tables in current context\n",
    "- extract column data via symbol indexting (dot notation does not work): tableName ``colName\n",
    "- Operations that work on splayed tables:\n",
    "    - select and exec (exec does not work on partitiond tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:/home/iguana/1_Code/4_jupyter_projects/q4m3_tutorial/data/testTrades/\n"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".kin.dirHandle set .kin.mktrades[`googl`ibm`fb`tmobil`amazn`alibaba;100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "04:12:55.527 06:03:01.029 01:11:42.896 09:21:44.893 17:12:24.021 21:11:04.805..\n"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testTrades `time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.5. Operations on a splayed directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- select\n",
    "- exec\n",
    "- upsert\n",
    "- xasc\n",
    "- ``attr#\n",
    "- updates applied to a mapped table are only applied in the memory not on the disk -> updates are not persistant\n",
    "    - and there are no built-in operations to update data in a persisted table, only workarounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.6. Appending to a splayed table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use upsert to append records to a splayed table:\n",
    "    - directoryHandle + upsert + table2Name (that contains the rows to be appended)\n",
    "        - schema of the two tables must match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.7. Manual operations on a splayed directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is only file system operations -> inconsistency may occur:\n",
    "    - Do this only when no queries are executed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "`:/db/t/ set ([] ti:09:30:00 09:31:00; p:101.5 33.5)\n",
    "`:/db/t/p set .[get `:/db/t/p; where 09:31:00=get `:/db/t/ti; :;42.0] / replace item at depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding a new column to a splayed table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "`:/db/t/s set (count get `:/db/t/ti)#`\n",
    "`:/db/t/.d set get[`:/db/t/.d] union `s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To delete a column, remove the column file and revise the .d file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system \"rm /db/t/s\"\n",
    "`:/db/t/.d set get[`:/db/t/.d] except `s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sorting a splayed table. E.g.:\n",
    "    - create sort index (iasc, idesc)\n",
    "    - re-index all column files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs:system \"ls /db/t\"\n",
    "I:idesc `:/db/t/ti\n",
    "{pth set get[pth:hsym `$\"/db/t/\",x] I} each cs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.8. Working with sym files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What can be done by manupulating the sym files?\n",
    "    1. Moving a table from one database to another\n",
    "    2. Change column type from symbol to string\n",
    "    3. Consolidating enumeration domains\n",
    "- The sym file can easily be corrupted: always backup database before modifying the sym file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Moving tables between databases:\n",
    "- un-enumerate table in source database\n",
    "- re-enumerate table in target database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.9. Splayed tables with link columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.10. Query execution on splayed tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When the same column is used in separate queries, it is loaded into memory only once and cached in memory until it is garbage collected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.3. Partitioned tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Table partitioning is the 2nd type of table decomposing in q. It is useful when the database is so large even one column cannot fit into the memory.\n",
    "- E.g.: slice columns into daily partitions\n",
    "- __ALL PARTITIOND TABLES ARE SPLAYED__, but not all splayed table are partitioned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.1. Partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Partitioning a splayed table is further decomposing it by grouping records having common values along a column of a special type.\n",
    "- Along columns of only this special type can partitioning be made.\n",
    "- The special type is any type that has an integer under the covers:\n",
    "    - boolean, 0b-1b, 1, ``boolean\n",
    "    - short\n",
    "    - int\n",
    "    - long\n",
    "    - char\n",
    "    - timestamp\n",
    "    - date\n",
    "    - timespan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A partitioned table is 2-dimensional persisted form, it is cut horizontally and vertically:\n",
    "- Partitions are stored in separate directories in the root directory\n",
    "- and each partition-directory contains a subdirectory with the name of the table, which contains the splayed files:\n",
    "/root\n",
    "    /partitionvalue1\n",
    "        /tablename\n",
    "            .d\n",
    "            column1name\n",
    "            column2name\n",
    "            …\n",
    "    /partitionvalue2\n",
    "        /tablename\n",
    "            .d\n",
    "            column1name\n",
    "            column2name\n",
    "            …\n",
    "        …"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kdb creates a virtual column for the partition variable. Its name cannot be controlled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.2. Partition domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kdb can have only a single partition domain\n",
    "- If you need different granularity of a table, you need to create two separate databases\n",
    "- How to partition the table?\n",
    "    - Choose partition granularity based on what kind of units are most frequently queried"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.3. Creating partitioned tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.4. Working with partitioned tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You cannot do these operations on a partitioned table:\n",
    "    - retreive an entire row or a column (for obvious reasons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exec does not work on partitioned tables, but there is a workaround:\n",
    "    - exec … from select … from … "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Always place the partition constraint first in a where clause with multiple conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.5. The virtual column i in partitioned tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- virtual column i refers to the relative row number within a partition, not the absolute one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.6. Qurey execution on partitioned tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Columns are loaded into memory as follows:\n",
    "    - kdb analyses the where phrase to determine which partitions are targeted by the query\n",
    "    - processes the remaining where phrases the subdomains that must be loaded\n",
    "    - processes the query separately against the requisite partitions to obtain partial results\n",
    "    - combines the partial results to obtain the final result\n",
    "- You can speed up the query execution by starting q with slaves. In this case the query will be executed concurrently, one partition per slave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.7. Map-reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Map-reduce in general:\n",
    "    - m-r decomposes an operaion on a list into two sub-operations: map and reduce:\n",
    "        - 1st step: op_map performed on each sublist -> list of partial results\n",
    "        - 2nd step: op_reduce is performed on the combined partial results list\n",
    "- Map-reduce for aggregation in queries, examples:\n",
    "    - Computing sum of partitioned columns: computes sums for partitions then adds them up\n",
    "    - Average: compute sum and count for partitions then calculates the average\n",
    "- Exercise: do a sorting on a partitiond table (use recursion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Map-reduce in queries on partitioned tables:\n",
    "    - The challenge is to decompose the query into a map step and a reduce step.\n",
    "    - The solution depends on whether the query involves aggregation or not.\n",
    "    - No aggregation:\n",
    "        - produces a partial result table: the result of the query on each partition is the computed columns for the list of records in the partition matching the constraint\n",
    "        - all the partial result tables conform, so you can take the __union__ of the partial result tables in order of their virtual partition column values\n",
    "    - Yes aggregation:\n",
    "        - Kdb+ recognizes the following aggregate functions to be map-reducible:\n",
    "            - avg, cor, count, cov, dev, distinct, first, last, max, med, min, prd, sum, var, wavg, wsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.8. Multiple partitioned tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There can be only one partition domain in a given kdb+ root, but\n",
    "- Multiple tables can share the same partitioning\n",
    "    - All partitions must contain slices of all tables (they do not need to be populated, though)\n",
    "        - Solution: create an empty copy of the table where it does not contain data\n",
    "        - Warning: if you do not create a partition for a table, it will be __removed__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "/root\n",
    "    /partitionvalue1\n",
    "        /tablename1\n",
    "            .d\n",
    "            column1name\n",
    "            column2name\n",
    "            …\n",
    "        /tablename2\n",
    "            .d\n",
    "            differentColumn1name\n",
    "            differentColumn2name\n",
    "            …\n",
    "    /partitionvalue2\n",
    "        /tablename1\n",
    "            .d\n",
    "            column1name\n",
    "            column2name\n",
    "            …\n",
    "        /tablename2\n",
    "            .d\n",
    "            differentColumn1name\n",
    "            differentColumn2name\n",
    "            …\n",
    "        …"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- See example [here](https://code.kx.com/q4m3/14_Introduction_to_Kdb+/#1438-multiple-partitioned-tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.9. Examples of other partition domain types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- See examples [here](https://code.kx.com/q4m3/14_Introduction_to_Kdb+/#1439-examples-of-other-partition-domain-types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.10. Partitioned tables with links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create links between tables in the same partitioned database.\n",
    "- Restriction __only intra-partion links__ are allowed: a link column in a table partition can only refer to another table's partition in the same partition directory\n",
    "    - E.g.: table partitions from the same day/month/year\n",
    "- See example [here](https://code.kx.com/q4m3/14_Introduction_to_Kdb+/#14310-partitioned-tables-with-links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.4. Segmented tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Performance gain through partitioning can only be achieved when the queries are not I/O-bound, but in most cases they are.\n",
    "- To speed up I/O-bound queries, the solution requires multiple I/O channels, so data retreival and processing can occur in parallel.\n",
    "- The third form of data decomposition, segmentation solves exactly this problem by creating different segments in different directories (on different hard disk partitions) above the partition directory layer and assigns separate threads to separate segments corresponding to separate I/O channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Table segmentation is an additional level on top of partitioning\n",
    "- Segmentation spreads a partitiond table's records across multiple directories that have the same sturcture as the root directory in a partitioned database\n",
    "- Each pseudo-root is called a segment, which are __directories containing a collection of partition directories__.\n",
    "- The segment directories are on independent I/O channels so that data retreival and processing can occur in parallel.\n",
    "- Any criteria can be used to decompose partitions into segments as long as results are conforming record subsets that are __disjoint and complete__ (they reconstitute the original table with no omissions or duplication).\n",
    "- Segmentation can happen\n",
    "    - along rows,\n",
    "    - partitions or\n",
    "    - a combination of them\n",
    "    - but cannot occur only along cloumns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A segmented table has a 3-dimensional persisted form:\n",
    "    - cut vertically by splaying\n",
    "    - cut horizontally by partitioning\n",
    "    - cut across physical locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The segment directories must not reside under the root\n",
    "- Only the sym file and the par.txt can reside in the root dirextory:\n",
    "    - the par.txt contains the paths of the physical locations of the segments"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "/db\n",
    "    [sym]\n",
    "    par.txt\n",
    "=============== <- channel 1\n",
    "/segment1\n",
    "    /partition*\n",
    "        /table*\n",
    "        /table*\n",
    "        …\n",
    "    /partition*\n",
    "        /table*\n",
    "        /table*\n",
    "        …\n",
    "=============== <- channel 2\n",
    "/segment2\n",
    "    /partition*\n",
    "        /table*\n",
    "        /table*\n",
    "        …\n",
    "    /partition*\n",
    "        /table*\n",
    "        /table*\n",
    "        …\n",
    "=============== …"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example1 for segmantation:\n",
    "    - where segmentation is __orthogonal to partitioning__: one segment belongs to only one partition\n",
    "        - segmentation and partitioning happens along the same variable: date\n",
    "    - segment the table by bucketing trades into alternating days of the week:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "/1                  <- drive 1\n",
    "    /2015.01.01\n",
    "        /t          <- day’s trades\n",
    "    /2015.01.03\n",
    "        /t          <- day’s trades\n",
    "    …\n",
    "=============\n",
    "/2                  <- drive 2\n",
    "    /2015.01.02\n",
    "        /t          <- day’s trades\n",
    "    /2015.01.04\n",
    "        /t          <- day’s trades\n",
    "    …"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- E.g.2:\n",
    "    - segment by alphabet: symbols from a-m and n-z are in separate segments\n",
    "- E.g.3:\n",
    "    - segment by stock exchange: symbols from a particular stock exchange are in the same segment\n",
    "- In example 2 and 3 segmentations are __NOT orthogonal to partitioning__:\n",
    "        - one partition is divided into/span across multiple segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- E.g.4: non-uniform segmentation:\n",
    "    - Some partition span segments, some do not"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "/seg A              <- drive 1\n",
    "    /2015.01.01\n",
    "        /t          <- entire day’s trades\n",
    "    /2015.01.02\n",
    "        /t          <- morning trades\n",
    "=============\n",
    "/seg B <- drive 2\n",
    "    /2015.01.02\n",
    "        /t          <- afternoon trades\n",
    "    /2015.01.03\n",
    "        /t          <- entire day’s trades\n",
    "=============\n",
    "/seg C <- drive 3\n",
    "    /2015.01.04\n",
    "        /t          <- entire day’s trades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4.2. Segmentation vs. partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SEE COMPARISON MATRIX HERE](https://code.kx.com/q4m3/14_Introduction_to_Kdb+/#1442-segmentation-vs-partitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4.3. Creating segmented tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MISSING: see examples here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4.4. Multiple segmented tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Multiple tables that share the same partition can also be segmented.\n",
    "- These tables can be distributed differently across the segmentation\n",
    "- However, if you want to use links or joins between these segmented tables, you have to distribute them similarly across the different segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example of table t and q distributed similarly across different segments:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "/a_m <- segment for first portion of alphabet\n",
    "    /2015.01.01     <- the specific day\n",
    "        /t          <- that day’s trades for symbols a-m\n",
    "        /q          <- that day’s quotes for symbols a-m\n",
    "    /2015.01.02     <- the specific day\n",
    "        /t          <- that day’s trades for symbols a-m\n",
    "        /q          <- that day’s quotes for symbols a-m\n",
    "=================\n",
    "/n_z                <- segment for second portion of alphabet\n",
    "    /2015.01.01     <- the specific day\n",
    "        /t          <- that day’s trades for symbols n-z\n",
    "        /q          <- that day’s quotes for symbols n-z\n",
    "    /2015.01.02     <- the specific day\n",
    "        /t          <- that day’s trades for symbols n-z\n",
    "        /q          <- that day’s quotes for symbols n-z\n",
    "=================\n",
    "\n",
    "--- corresponding par.txt file:\n",
    "/a_m\n",
    "/n_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- See example [here](https://code.kx.com/q4m3/14_Introduction_to_Kdb+/#1444-multiple-segmented-tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Starting q with slaves__:\n",
    "    - $$q -s 2 / 2 is the number of slaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// use peach to run processes in parallel\n",
    "aj1:{aj[`sym`ti;select from t where date=d; select from q where date=d]}\n",
    "raze aj1 peach 2015.01.01 2015.01.02\n",
    "raze aj1 peach 2015.01.01 2015.01.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4.5. Query execution against segmented tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Design principles for segmentations:\n",
    "    1. Maximize the number of independent I/O channels to retrieve data in parallel: n (several hdds or sdds)\n",
    "    2. Maximize server memory to allocate each slave thread as much memory as it needs\n",
    "    3. Create n segments to spread data retrieval across the n I/O channels\n",
    "    4. Open at least n slave threads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In such an environment, kdb decomposes a query into two steps of mapping and reducing:\n",
    "    - Map: a revised form of the original query that executes on each segment\n",
    "    - Reduce: aggregate the segment results\n",
    "- This results in preliminary calculations close to the data as possible while performing the aggregation centrally at the last step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Parallel query execution of map-reduce operations on segmented tables__:\n",
    "    - Step 1: Determinining the __target partition footprint__ on each segment\n",
    "        - kdb+ compares the query’s requisite partitions to the segment layout in par.txt.\n",
    "        - __The result is a nested list__, each item being the partition list for one segment.\n",
    "    - Step 2: __Map step execution__ in a specific segment:\n",
    "        - kdb+ creates a revised query containing the map sub-operation from the original query,\n",
    "        - __peach__: command dispatches the revised query to all n slaves.\n",
    "            - Each slave is provided the partition list created in _step 1_ for one segment and\n",
    "            - each slave computes the revised query for its dedicated segment.\n",
    "            - For example, the revised query for avg is: \"Compute the sum and count of the sublist\"\n",
    "\n",
    "- __Query execution within one slave/segment__:\n",
    "    - In a single slave, the revised query is applied against a segment’s partition footprint.\n",
    "    - Here kdb+ sequentially applies the map sub-operations of the original query across the targeted partitions to obtain partition result tables,\n",
    "    - then these result tables are collected into a list representing one segment result.\n",
    "- __Query execution across slaves/segments__ ignoring partition details:\n",
    "    - At this level, the original query’s map step has n slaves\n",
    "        - retrieving segment data in parallel and\n",
    "        - calculating segment results.\n",
    "    - __Raze__: command flattens the nested list of segment results and\n",
    "    - __which command???__: reorders the segment results by partition value.\n",
    "- __Original reduce step__ is applied to combine the full list of ordered partition results into the query result table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4.6. Balancing slaves and cores: channel and core utilization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To achieve 100% saturation of I/O and CPU, we have to optimize slaves and cores.\n",
    "- __These are only guidelines__:\n",
    "- __Kdb uses only as many slaves to process the query as there are segments in the query footprint__\n",
    "- There are two cases:\n",
    "    - __I/O bound optimization__: when the query has light calculation requirement but intensive I/O load:\n",
    "        - use n channels => n segments => n slaves => n cores\n",
    "        - Example: Volume Weighted Average Price (VWAP) calculation\n",
    "    - __Balanced I/O-compute__: both I/O and calculation are intensive:\n",
    "        - in this design,\n",
    "            - while one slave waits for the data to be loaded via one channel, another slave on the same core can do the computation on data already in memory\n",
    "            - and vice versa: one slave is crunching data already loaded into memory, another slave can do the loading of another segment through a free channel\n",
    "        - So to maximize channel and core utilization, we want two slaves on each core, and two segments for or each channel:\n",
    "            - __n channels => 2n segments => 2n slaves => n cores__\n",
    "        - Example: regression analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In practice,\n",
    "    - start with one scenario,\n",
    "    - construct the initial configuration\n",
    "    - test it with your data, typical queries and\n",
    "    - simulate a realistic user load\n",
    "    - monitor the I/O saturation and CPU utilization\n",
    "    - adjust the number of slaves and cores allocated to the q process accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4.7. Sample performance data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- See example [here](https://code.kx.com/q4m3/14_Introduction_to_Kdb+/#1447-sample-performance-data) for a configuation of slaves and segments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.5. [Utilities for splaying and partitioning](https://code.kx.com/q4m3/14_Introduction_to_Kdb+/#145-utilities-for-splaying-and-partitioning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __.Q.namespaces__ contain the functions for creating and maintaining splayed and partitioned tables\n",
    "- Kx do not support for the customer use of functions in the .Q namespace, still, everybody uses them\n",
    "- [Referenc for the functions](https://code.kx.com/v2/ref/#q) in the .Q namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- .Q.qp: is partitioned\n",
    "- [.Q.en](https://code.kx.com/v2/kb/splayed-tables/#enumerating-varchar-columns-in-a-table): enumerate varchar columns (of symbol type)\n",
    "- [.Q.pv](https://code.kx.com/q4m3/14_Introduction_to_Kdb+/#1453-qpv): list of partition slice directories in the database found in the root\n",
    "- .Q.ind: getting individual rows of a partitioned table by index:\n",
    "    - .Q.ind[trade;til 100] is the same for a partitioned table as 'select from table where i<100' for an in-memory table\n",
    "- .Q.k: returns interpreter version number used in the process\n",
    "- .Q.l: the functional implementaion of \\l\n",
    "- .Q.M: returns long integer infinity 0W~.Q.M\n",
    "- .Q.MAP: keep partitions mapped to memory to avoid repeated file system calls during a select\n",
    "    - usage: \\l /dirName/ then .Q.MAP\n",
    "    - not recommended to use with compressed files\n",
    "- .Q.opt .z.x: returns dictionary of command line arguments\n",
    "- .Q.dpft: The utility .Q.dpft assists in creating partitioned and segmented tables by incorporating the functionality of .Q.en at a slightly higher level. It is convenient when partitions are loaded and written out iteratively.\n",
    "- .Q.fs: process large txt files (that do not fit into memory) in chunks\n",
    "- .Q.fsn: returns chunk size as additional parameter\n",
    "- .Q.chk: writes empty splayed splice of a table in a partition directory where it is missing\n",
    "- .Q.view: for executing queries against partitond or segmented tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.6. Kdb database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.6.1 Comparing kdb+ to an RDBMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fundamental difference:\n",
    "    - Tables are based on:\n",
    "        - Kdb: lists (ordered with duplicate elements)\n",
    "        - SQL: sets (unordered, distinct elements)\n",
    "    - Data format for storage:\n",
    "        - Kdb: as contiguous items in column lists\n",
    "        - RDBMS: as fields with non-contiguous rows\n",
    "    - Tables operations:\n",
    "        - Kdb: vector operations on columns\n",
    "        - SQL: scalar operations on individual fields and rows\n",
    "- More differences:\n",
    "    - Table creation:\n",
    "        - Kdb: functionally in q language\n",
    "        - SQL: defined declaratively in DDL on disks\n",
    "    - Data persistence:\n",
    "        - Kdb: Serialized q entities stored in O/S file system; no separate metadata\n",
    "        - SQL: tables and related metadata stored in an opaque repository by row\n",
    "    - Data access:\n",
    "        - Kdb: direct data access in q. Query forms are in q-sql for table manupulation\n",
    "        - SQL: DDL for accessing metadata; SQL as language for accessing data\n",
    "    - Memory residence:\n",
    "        - Kdb: table in memory but can be persisted to disk. columns subsets are page faulted into memory for mapped tables\n",
    "        - SQL: Tables reside on disk; query result sets reside in program memory\n",
    "    - Data modification in memory:\n",
    "        - Kdb: memory resident tables modifiable via q and q-sql\n",
    "        - SQL: no data modification in memory\n",
    "    - Data modification on disks:\n",
    "        - Kdb: only with append (upsert) via q\n",
    "        - SQL: INSERT, UPDATE via SQL\n",
    "    - Data programming:\n",
    "        - Kdb: programs written in q, which is an integrated vector functional programming language; tables are first class entities\n",
    "        - SQL: declarative relational programming language; programs are stored procedures written in proprietary procedural language\n",
    "    - Transactions:\n",
    "        - Kdb: no built-in transaction support\n",
    "        - SQL: support for transactions via COMMIT and ROLLBACK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.6.2 The Physical Layout of a kdb+ Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A kdb+ database is a file system directory and its subdirectories holding q entities.\n",
    "- The root directory is the root of the databse\n",
    "- All constituents of the database are q entities saved in files\n",
    "- Database entities\n",
    "    - either reside at some level under the root (splayed and partitioned tables)\n",
    "    - or referenced in the par.txt file under the root (segmented tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.6.2.1. The sym file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The sym file is an optional serialized q data file\n",
    "    - containing a list of unique symbols\n",
    "        - that are used as the domain for symbol enumeration\n",
    "- Placing the sym file in the root directory uarantees that it will be loaded into memory at startup\n",
    "- According to convention: all symbol columns from all tables are enumerated over a single domain sym\n",
    "    - It os allowed over multiple domain syms, however .Q utilities handling symbol enumeration work only with single domain syms\n",
    "    - With symbols in muliple domains, the ~ function won't work because they will have different enumeration types\n",
    "- Corrupting the sym file will ressult in irresolvable symbol columns in the database:\n",
    "    - Safegueards:\n",
    "        - use conditional enumeration (``fileHandle/sym? or the appropriate .Q utilities: .Q.en etc.)\n",
    "        - built-in file locking to mediate concurrent updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.6.2.2 Other Serialized Files in Root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- By placing any serialized q entity into the root directory, you can have it loaded into a file with the same name\n",
    "- E.g a small sized keyed table can be initialized this way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.6.2.3 Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Any q code in the root directory can be loaded on starup:\n",
    "- E.g.: functions defined in such a script can be viewed as stored procedures for the database\n",
    "- Alternatively, you can create QINIT directory and place all your files in it that you want to load upon q process startup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.6.2.4 Splayed tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- spayed table directories must be immediately under the root\n",
    "- all columns are mapped into memory, but only a few of them will reside simultaneously in the memory\n",
    "- recently accessed columns are cached by the OS; this has a performance close to that of in-memory tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.6.2.5 Partitioned tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Partition directories should also be under the root directory\n",
    "- They must have a uniform structure:\n",
    "    - must contain splayed directories for all tables in the partition even if they have no data in that partition -> splay en empty schema for a table with no records for a partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.6.2.6 Segmented tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No records of a segmented table can reside under the root directory\n",
    "- Only the par.txt file can be in the root with one entry per line\n",
    "    - each entry represents an os path for a segment directory containing the segment for the data in the segment\n",
    "- Symlinks can also be in the root directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.6.3. Creating and populating a kdb+ database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Point q to a directory at startup\n",
    "    - $$: q directoryName/ or\n",
    "    - \\l /directoryName\n",
    "- That directory becomes the root directory for the kdb+ database and also the current working directory for the OS. We shall refer to this scenario as kdb+ startup to distinguish it from an arbitrary q session. We shall cover the items that Kdb+ startup finds in the order that it handles them:\n",
    "    - Serialized q entities\n",
    "    - Splayed tables\n",
    "    - Partitioned or segmented tables\n",
    "    - Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.6.3.2 Serialized q entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Serialized data files are loaded into a variable with the same name of the file\n",
    "    - E.g.: sym file\n",
    "- Only load data files that are in the root\n",
    "- Files with extensions in their names will not be loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.6.3.3 Splayed tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Subdirectories under the root directory recognized as a splayed table are mapped into memory automatically at startup (sym file should be in the root directory containing all symbol type columns in the table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.6.3.4 Partitioned tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Subdirectories of root folder recognized as valid partition values are also mapped\n",
    "- Root can contain both partitioned and splayed subdirectories\n",
    "- Partitioned and segmented tables are mutually exclusive???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.6.3.5 Segmented tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kdb identifies the presence of segmented tables through the presence of a par.txt file, which contains the paths to the different segments of the table.\n",
    "- Valid segmented tables then mapped into memory\n",
    "- Both segmented and splayed tables can be in the root directory\n",
    "- Partitioned and segmented tables are mutually exclusive???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.6.3.6 Scripts (fileName.q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Files with the .q extention are interpreted as q scipts\n",
    "- Files with the .k extention are interpreted as k scipts\n",
    "- Best practice: put one script file in the root, which contains the paths to files to be loaded in the order we to want them to be loaded\n",
    "- Invalid code in the scipt aborts the loading of the whole script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.7. Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example code for creating a partitioned database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/ create serialized variables\n",
    "`:/db/LIFE set 42\n",
    "`:/db/f set {x*y}\n",
    "`:/db/lookup set ([s:`a`b`c] v:1 2 3)\n",
    "\n",
    "/ create splayed tables\n",
    "`:/db/tref/ set ([] c1:1 2 3; c2:1.1 2.2 3.3)\n",
    "`:/db/cust/ set .Q.en[`:/db;] ([] sym:`ibm`msft`goog; name:`:/db/sym?`oracle`microsoft`google)\n",
    "\n",
    "/create partitioned tables\n",
    "`:/db/2015.01.01/t/ set .Q.en[`:/db;] ([] ti:09:30:00 09:31:00; sym:`ibm`msft; p:101 33f)\n",
    "`:/db/2015.01.02/t/ set .Q.en[`:/db;] ([] ti:09:30:00 09:31:00; sym:`ibm`msft; p:101.5 33.5)\n",
    "`:/db/2015.01.01/q/ set .Q.en[`:/db;] ([] ti:09:30:00 09:31:00; sym:`ibm`msft; b:100.75 32.75; a:101.25 33.25)\n",
    "`:/db/2015.01.02/q/ set .Q.en[`:/db;] ([] ti:09:30:00 09:30:00; sym:`ibm`msft; b:101.25 33.25; a:101.75 33.75)\n",
    "\n",
    "/ create load script\n",
    "`:/db/init.q 0: (\"TheUniverse:42\";\"\\\\l /lib/math.q\";\n",
    " \"\\\\l /lib/expr.q\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example code to create a segmented database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/ create serialized variables\n",
    "`:/db/LIFE set 42\n",
    "`:/db/f set {x*y}\n",
    "`:/db/lookup set ([s:`a`b`c] v:1 2 3)\n",
    "\n",
    "/ create splayed tables\n",
    "`:/db/tref/ set ([] c1:1 2 3; c2:1.1 2.2 3.3)\n",
    "`:/db/cust/ set .Q.en[`:/db;] ([] sym:`ibm`msft`goog; name:`oracle`microsoft`google)\n",
    "\n",
    "/ create segmented tables\n",
    "extr:{[t;r] select from t where (`$1#'string sym) within r}\n",
    "t:.Q.en[`:/db;] ([] ti:09:30:00 09:31:00; sym:`ibm`t; p:101 17f)\n",
    "q:.Q.en[`:/db;] ([] ti:09:29:59 09:29:59 09:30:00; sym:`ibm`t`ibm; b:100.75 16.9 100.8; a:101.25 17.1 101.1)\n",
    "`:/am/2015.01.01/t/ set extr[t;`a`m]\n",
    "`:/nz/2015.01.01/t/ set extr[t;`n`z]\n",
    "`:/am/2015.01.01/q/ set extr[q;`a`m]\n",
    "`:/nz/20015.01.01/q/ set extr[q;`n`z]\n",
    "t:.Q.en[`:/db;] ([] ti:09:30:00 09:31:00; sym:`t`ibm; p:17.1 100.9)\n",
    "q:.Q.en[`:/db;] ([] ti:09:29:59 09:29:59 09:30:00; sym:`t`ibm`t; b:17 100.7 17.1;a:17.2 101.25 17.25)\n",
    "`:/am/2015.01.02/t/ set extr[t;`a`m]\n",
    "`:/nz/2015.01.02/t/ set extr[t;`n`z]\n",
    "`:/am/2015.01.02/q/ set extr[q;`a`m]\n",
    "`:/nz/2015.01.02/q/ set extr[q;`n`z]\n",
    "\n",
    "`:/db/par.txt 0: (\"/am\"; \"/nz\")\n",
    "\n",
    "/ create load script\n",
    "`:/db/init.q 0: (\"TheUniverse:6*7\"; \"\\\\l /lib/math.q\"; \"\\\\l /lib/expr.q\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.8. QHOME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.8.1. Envitonment variables (QHOME, QLIC, QINIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Three environment variables QHOME, QLIC and QINIT are used by kdb+ at startup.\n",
    "- __QHOME__ specifies the directory where kdb+ expects to find the bootstrap file q.k. By default, it also looks there for the license file k4.lic. If QHOME is not defined, kdb+ falls back to $HOME/q for Unix-based systems and c:\\q for Windows.\n",
    "- __QLIC__ overrides the default location for the license file. If QLIC is not defined, kdb+ falls back to QHOME (or its fallback).\n",
    "- __QINIT__ specifies the name of the file that is executed immediately after the load of q.k. If QINIT is not defined, kdb+ attempts to load the file __q.q__ from QHOME. If QHOME is not defined or q.q is not found, no error is reported.\n",
    "    - QINIT is executed in the root context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.8.2. q in the hood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Starting a q session without specifying a working directory with a bare 'q' command, sets the working directory to the current directory\n",
    "- loading a scipt outside of the working root directory does not change the root directory\n",
    "- loading a database cahges the current directory to the database root\n",
    "- q -u: determines the files hierarchy visibility\n",
    "- when loading a file without specifying its path,\n",
    "    - first, q searches for it in the current directory, if not found\n",
    "    - second, in QHOME, if not found,\n",
    "    - third, in $HOME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPENDIX A: [Built-in functions](https://code.kx.com/q4m3/A_Built-in_Functions/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions I already used and know\n",
    "- Communication with OS\n",
    "    - getenv ``environmentVariableName: returns environment variable value\n",
    "    - setenv: `varName setenv varValueAsString\n",
    "    - system\n",
    "- Communicating with the q interpreter:\n",
    "    - parse\n",
    "    - eval\n",
    "    - eval parse someQEntity\n",
    "- String manupulation\n",
    "    - ss:\n",
    "    - ssv\n",
    "    - like\n",
    "    - sv: join\n",
    "    - vs: split\n",
    "    - upper\n",
    "- Data structure manipulation:\n",
    "    - raze for lists\n",
    "    - ungroup for tables\n",
    "    - idesc\n",
    "    - iasc\n",
    "    - where\n",
    "    - whithin\n",
    "- Mathematical functions\n",
    "    - til:\n",
    "    - var:\n",
    "    - sum:\n",
    "    - avg:\n",
    "    - wavg: weighted average\n",
    "    - wsum: weighted sum\n",
    "    - xrank: for computing quantiles\n",
    "- Multiple overloaded functions:\n",
    "    - value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX B: [Error messages](https://code.kx.com/q4m3/B_Error_Messages/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.1. Runtime errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Access: you cannot read files above root directory or your usr/password is invalid\n",
    "- Assign: attempt to use a reserved word\n",
    "- Conn: too many incoming connections; max. 1022\n",
    "- Domain: argument out of domain; e.g.: til -1\n",
    "- Glim: limit of number of attributes is exceeded. There are no limits over q3.2\n",
    "- Length: incompatible list lengths\n",
    "- Limit:\n",
    "    - attempting to create a list longer than limit\n",
    "    - attempt to serialize object > 2GB\n",
    "- loop: circular reference loop; a::b::a\n",
    "- mismatch: columns cannot be aligned for operation\n",
    "- mlim: nested column limit 999 is exceeded\n",
    "- nyi: not yet implemented\n",
    "- os: operating system eror\n",
    "- pl: peach cannot handle parallel lambdas\n",
    "- Q7\n",
    "- rank: invalid rank or valence\n",
    "- type: wrin type\n",
    "- value: missing value\n",
    "- vd1: attempted multithread update\n",
    "- wsfull: memory allocation failed due to running out of swap or hitting -W limit\n",
    "- xxx: xxx undefind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024f\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 xexp 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.2. Parse errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- unpaired item: \")}[({]\n",
    "- branch: a branch more than 255 byte codes away\n",
    "- char: invalid character\n",
    "- constants: too many contants; max 96\n",
    "- globals: too many global variables: 255 max\n",
    "- locals: too many local variables: 24 max\n",
    "- params: too many parameters in function: 8 max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.3. System errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- xxx:yyy\n",
    "    - xxx is a kdb message. xxx can be:\n",
    "        - addr\n",
    "        - close\n",
    "        - conn\n",
    "        - p from -p\n",
    "        - snd\n",
    "        - rcv\n",
    "        - fileName (invalid)\n",
    "    - yyy is the OS message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.4. License errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cores: exceeded number of licensed cores\n",
    "- exp: expiry date passed\n",
    "- host: unlicensed host\n",
    "- k4.lic: k4.lic file not found\n",
    "- os: unlicensed os\n",
    "- srv: attempt to use client-only license in server mod\n",
    "- upd: attempt to use kdb version more tecent than update date\n",
    "- user: unlicensed user\n",
    "- wha: invalid system date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Q (kdb+)",
   "language": "q",
   "name": "qpk"
  },
  "language_info": {
   "file_extension": ".q",
   "mimetype": "text/x-q",
   "name": "q",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
